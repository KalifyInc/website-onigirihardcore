---
date: '2024-05-20:11:54:00'
title: OpenAI - ex-funcionário bota a boca no trombone após saída de fundador
description: 'Jan Leike, ex-funcionário da OpenAI e um dos membros do time de superalinhamento, publicou uma série de críticas à empresa após sua saída. Nesta sexta-feira (17), Leike foi ao X/Twitter explicar as razões de pedir demissão, assim como fez o cofundador da OpenAI, Ilya Sutskever.'
image: https://www.webfx.com/wp-content/uploads/2023/07/what-is-openai.png
categories: 'Technologies'
ytid: ''
author: "Anderson \"Yagasaki\" Marlon"
---

Jan Leike, ex-funcionário da OpenAI e um dos membros do time de superalinhamento, publicou uma série de críticas à empresa após sua saída. Nesta sexta-feira (17), Leike foi ao X/Twitter explicar as razões de pedir demissão, assim como fez o cofundador da OpenAI, Ilya Sutskever.

As saídas de Sutskever e de Jan Leike podem estar ligadas a divergências na condução da equipe de superalinhamento, cuja função é pesquisar e desenvolver meios para manter as IAs seguras. Ela também auxilia na regulação dessa tecnologia. Contudo, a direção da OpenAI estaria prejudicando o trabalho do time.

Sustskever, Leike e mais alguns funcionários comunicaram a saída da OpenAI na quarta-feira (15), de acordo com o TechCrunch. A nota de despedida do fundador e ex-cientista chefe da empresa tem tom amigável, assim como as mensagens escritas por Sam Altman, CEO da OpenAI, e Greg Brockman, presidente.

Contudo, as informações divulgadas por um fonte de empresa para o TechCrunch sugere que o clima dentro da OpenAI não era tranquilo — no sentido de haver um certo ressentimento entre Altman e Sutskever por causa da demissão do primeiro. Inclusive o próprio Leike foi ao X/Twitter sendo mais direto sobre as divergências dentro da OpenAI.

![](https://files.tecnoblog.net/wp-content/uploads/2024/05/jan-leike.png)

## Ex-funcionário alega que OpenAI não se preocupa com segurança
Em uma série de tweets, Jan Leike alega que a OpenAI tomou rumos diferentes nos últimos anos. Ele afirma que a empresa jogou a cultura de segurança no “banco de trás”. Também relata que estava em desacordo com as lideranças há tempo, mas ficou insustentável nos últimos dias.

O pesquisador, que já passou pela DeepMind, a empresa de IA do Google, diz acreditar que muito da capacidade computacional da OpenAI deveria ser usada para preparar as próximas gerações de LLM em segurança, gestão de risco, impacto social e outros temas.

“Esses problemas são difíceis de resolver e não sinto que estamos no caminho para chegar lá”, diz Leike. Entre as publicações, o pesquisador destaca que criar uma máquina mais inteligente que os humanos é um negócio arriscado.

![](https://files.tecnoblog.net/wp-content/uploads/2023/01/inteligencia-artificial-1-1060x596.jpg)

Isso pode soar como algo do universo Exterminador do Futuro, mas o risco mais real e mais próximo de uma IA geral está ligado a uma crise social. Caso a tecnologia avance rapidamente, muitas pessoas perderão o emprego em pouco tempo. E esse é um dos principais pontos do tema de regulação das IAs, um dos escopos do time de superlinhamento da OpenAI.

Quando o time foi criado, foi prometido que 20% da capacidade computacional da OpenAI seria dedicada as suas tarefas. No entanto, conforme apurado pelo TechCrunch, a equipe geralmente tinha seus pedidos negados, o que impedia seu trabalho.
